{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Assignment - 2 Language Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will import the necessary libraries and read all the text from the file and then parse it using the sentence tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "\n",
    "with open(\"sherlock.txt\", 'r') as text_file:\n",
    "    text = text_file.read()\n",
    "    text = text.replace('\\n',' ')\n",
    "    text = text.lower()\n",
    "\n",
    "lines = sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will randomly divide the dataset in 80/20 ratio for training and testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6813\n",
      "5450\n",
      "1363\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "testing_data = []\n",
    "for i in range(len(lines)):\n",
    "    testing_data.append(lines[i])\n",
    "\n",
    "training_data =[]\n",
    "\n",
    "for i in range(round(len(lines)*0.8)):\n",
    "    rand=random.choice(testing_data)\n",
    "    training_data.append(rand)\n",
    "    testing_data.remove(rand)\n",
    "    \n",
    "print(len(lines))\n",
    "print(len(training_data))\n",
    "print(len(testing_data))\n",
    "#print(training_data) #Remove # to print training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[]\n",
    "del_lst=[',','.',\"'s\",'\"','“','”',':','--',\"'\",\"!\",\"''\",'``',';']\n",
    "for i in range(len(training_data)):\n",
    "    words.append('<s>')\n",
    "    words_in_line=word_tokenize(training_data[i])\n",
    "    for j in range(len(words_in_line)):\n",
    "        if words_in_line[j] not in del_lst:\n",
    "            words.append(words_in_line[j])\n",
    "    words.append('</s>')\n",
    "    \n",
    "#print(words) #Remove # to print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing MLE for unigrams,bigrams,trigrams and quadgrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7494\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "unigram = Counter()\n",
    "for i in words:\n",
    "    if i not in unigram.keys():\n",
    "        unigram[i]=1\n",
    "    else:\n",
    "        unigram[i]+=1\n",
    "\n",
    "#print(unigram) #Remove # to print\n",
    "n_unigram=len(unigram)\n",
    "print(n_unigram)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculates the mle for unigrams using original counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02827087442472058\n"
     ]
    }
   ],
   "source": [
    "def unigram_mle(word):\n",
    "    return unigram[word]/(n_unigram)\n",
    "\n",
    "#Example\n",
    "print(unigram_mle('little'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram=Counter()\n",
    "\n",
    "for i in range(len(words[:-1])):\n",
    "    if (words[i],words[i+1]) not in bigram.keys():\n",
    "        bigram[(words[i],words[i+1])]=1\n",
    "    else:\n",
    "        bigram[(words[i],words[i+1])]+=1\n",
    "\n",
    "#print(bigram) #Remove # to print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculates the mle for bigrams using original counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.14482758620689656\n"
     ]
    }
   ],
   "source": [
    "def bigram_mle(words):\n",
    "    return bigram[words]/unigram[words[0]]\n",
    "\n",
    "#Example\n",
    "print(bigram_mle(('sherlock', 'holmes')))\n",
    "print(bigram_mle(('have', 'been')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram=Counter()\n",
    "for i in range(len(words[:-2])):\n",
    "    if (words[i],words[i+1],words[i+2]) not in trigram.keys():\n",
    "        trigram[(words[i],words[i+1],words[i+2])]=1\n",
    "    else:\n",
    "        trigram[(words[i],words[i+1],words[i+2])]+=1\n",
    "\n",
    "#print(trigram) #Remove # to print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculates the mle for trigrams using original counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n"
     ]
    }
   ],
   "source": [
    "def trigram_mle(words):\n",
    "    return trigram[words]/bigram[words[:2]]\n",
    "\n",
    "#Example\n",
    "print(trigram_mle(('a', 'few', 'minutes')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quadgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "quadgram=Counter()\n",
    "for i in range(len(words[:-3])):\n",
    "    if (words[i],words[i+1],words[i+2],words[i+3]) not in quadgram.keys():\n",
    "        quadgram[(words[i],words[i+1],words[i+2],words[i+3])]=1\n",
    "    else:\n",
    "        quadgram[(words[i],words[i+1],words[i+2],words[i+3])]+=1\n",
    "\n",
    "#print(quadgram)  #Remove # to print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculates the mle for quadgrams using original counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3125\n"
     ]
    }
   ],
   "source": [
    "def quadgram_mle(words):\n",
    "    return quadgram[words]/trigram[words[:3]]\n",
    "\n",
    "#Example\n",
    "print(quadgram_mle(('upon', 'the', 'table', 'and')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating sentences given Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "but not easily controlled when i tossed a start that i question of the very carefully round him\n",
      "it looks this matter in which led into the colour they carried me down\n",
      "i heard uncle returned some hundreds of the centre by my fears she asked in the words to find that he locked your windows loomed behind a weapon\n",
      "i was it seems to pick for five o'clock that once more compunction about to return ticket in front of the gas-light that she would stay with him out in the road to a dash of him and stretched down to go when mr. windibank draws my heart that some ten miles of a rabbit into briony lodge to him\n",
      "how do\n",
      "but as it is willing to commit you see if so i did so\n",
      "you have come to the passage and a half-pay major freebody who wished to work ?\n",
      "good-bye it is really managed to the injuries\n",
      "it out of you may do\n",
      "she could send father of this is an advance it in his lodgings at home the beryl coronet had ever having her she 'have you you need of any such a few whispered words that our plans\n",
      "holmes glancing over the coronet had been attended to see that our lives though the ways and also discreet and perhaps just ask you did the early enough observed there was so\n",
      "i think then when we went into the time is important\n",
      "i was dated from your opinion is n't slip of this man of some paternal advice will be at our investigation\n",
      "and one laying out and ends on the heart of the reigning family seat as i have i exclaimed in the door slammed heavily timbered park stretched himself in an emigrant ship\n",
      "you remember aright at all gossip\n",
      "this morning drive out in front of interest in her face inside the box and sent for what in the lad slipped behind the darkness\n",
      "after he bowed solemnly he rose and of pennies varied by certain that frank was plainly furnished with them upon fold over with the door\n",
      "i will you can hardly believe that her secret that francis h. for nothing ?\n",
      "you raise the authorities to know that she was comparatively modern and concise\n",
      "has arrived almost as a tall gaunt woman whose character an average commonplace face blanched with a huge brown\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def bi_generate():\n",
    "    sent=\"<s>\"\n",
    "    start='<s>'\n",
    "    while(1):\n",
    "        lst=[]\n",
    "        for i in bigram.keys():\n",
    "            if i[0]==start:\n",
    "                lst.append(i)\n",
    "        plst=[bigram_mle(i) for i in lst]\n",
    "        tot=sum(plst)\n",
    "        plst=[i/tot for i in plst]\n",
    "        ans = list(np.random.multinomial(1,plst))\n",
    "        ind = ans.index(1)\n",
    "        \n",
    "        new_word = lst[ind][1]\n",
    "        sent=sent+\" \"+new_word\n",
    "        if (new_word=='</s>'):\n",
    "            break\n",
    "        else:\n",
    "            start = new_word\n",
    "    \n",
    "    return sent[4:-5]\n",
    "\n",
    "for i in range(20):\n",
    "    print(bi_generate())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "that is to be impossible but i am about to say there was not merely because my friend blowing blue rings into the dining-room and waited there in silence for some few minutes during which he bowed and turning away without having recovered her consciousness\n",
      "i read suspicion there and i turned and ran out again\n",
      "it not only proficient in his hands the value of which he treated the singular mystery which he had shown\n",
      "she impressed me neither favourably nor the reverse\n",
      "you hear\n",
      "i thought that he needed it\n",
      "there could be found in his chair with his head like a child by the heavy hall door and so systematic its methods that there are a most singular which i sold my character\n",
      "you interest me extremely said holmes answering the other hand he has cruelly wronged\n",
      "my sister voice\n",
      "i should like a coster orange barrow\n",
      "the vanishing cloth\n",
      "so they have been enough to shake my very heart\n",
      "then there are only just left\n",
      "'as governess ?\n",
      "'you have doubtless heard of him and we dashed down the lane and another little smudge of blood had fallen in while his deep-set bile-shot eyes and placed his finger in the hands of our expedition of to-day had nothing fit to wear it on\n",
      "i have now fled together\n",
      "he cried\n",
      "'oh said he\n",
      "my sister thinks that it\n",
      "there is really impossible for me in my uncle life in him\n"
     ]
    }
   ],
   "source": [
    "def tri_generate():\n",
    "    sent=\"<s>\"\n",
    "    lst=[]\n",
    "    for i in bigram.keys():\n",
    "        if i[0]=='<s>':\n",
    "            lst.append(i)\n",
    "    plst=[bigram_mle(i) for i in lst]\n",
    "    tot=sum(plst)\n",
    "    plst=[i/tot for i in plst]\n",
    "    ans = list(np.random.multinomial(1,plst))\n",
    "    ind = ans.index(1)\n",
    "        \n",
    "    new_word = lst[ind][1]\n",
    "    sent=sent+\" \"+new_word\n",
    "        \n",
    "    start=('<s>',new_word)\n",
    "    while(1):\n",
    "        lst=[]\n",
    "        for i in trigram.keys():\n",
    "            if i[0:2]==start:\n",
    "                lst.append(i)\n",
    "        plst=[trigram_mle(i) for i in lst]\n",
    "        ans = list(np.random.multinomial(1,plst))\n",
    "        ind = ans.index(1)\n",
    "        \n",
    "        new_word = lst[ind][-1]\n",
    "        sent=sent+\" \"+new_word\n",
    "        if (new_word=='</s>'):\n",
    "            break\n",
    "        else:\n",
    "            start = (start[1],new_word)\n",
    "    \n",
    "    return sent[4:-5]\n",
    "\n",
    "for i in range(20):\n",
    "    print(tri_generate())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she could not have been less than twenty i can quite understand your thinking so i said\n",
      "no legal papers or certificates ?\n",
      "he stammered\n",
      "of course in your position of unofficial adviser and helper to everybody who is absolutely puzzled throughout three continents you are brought in contact with all that is bizarre and outside the conventions and humdrum routine of everyday life\n",
      "no but this horrible man confessed to having been there and the lascar stoutly swore that no one was coming save the single gentleman whose eccentric conduct had drawn my attention\n",
      "said he 'i will not stand it any longer\n",
      "thick clouds of smoke curled through the room and closed the door tightly behind him\n",
      "they were found floating near the margin by a park-keeper\n",
      "i braved him to do the running down\n",
      "and now it is time that we arranged our little plans\n"
     ]
    }
   ],
   "source": [
    "def quad_generate():\n",
    "    \n",
    "    sent=\"<s>\"\n",
    "    lst=[]\n",
    "    for i in bigram.keys():\n",
    "        if i[0]=='<s>':\n",
    "            lst.append(i)\n",
    "    plst=[bigram_mle(i) for i in lst]\n",
    "    tot=sum(plst)\n",
    "    plst=[i/tot for i in plst]\n",
    "    ans = list(np.random.multinomial(1,plst))\n",
    "    ind = ans.index(1)\n",
    "        \n",
    "    new_word1 = lst[ind][1]\n",
    "    sent=sent+\" \"+new_word1\n",
    "    \n",
    "    ############################# added 1st word\n",
    "    \n",
    "    lst=[]\n",
    "    for i in trigram.keys():\n",
    "            if i[0:2]==('<s>',new_word1):\n",
    "                lst.append(i)\n",
    "    plst=[trigram_mle(i) for i in lst]\n",
    "    ans = list(np.random.multinomial(1,plst))\n",
    "    ind = ans.index(1)\n",
    "        \n",
    "    new_word2 = lst[ind][-1]\n",
    "    sent=sent+\" \"+new_word2\n",
    "    \n",
    "    ############################ added 2nd word\n",
    "    \n",
    "    start=('<s>',new_word1,new_word2)\n",
    "\n",
    "    while(1):\n",
    "        lst=[]\n",
    "        for i in quadgram.keys():\n",
    "            if i[0:3]==start:\n",
    "                lst.append(i)\n",
    "        plst=[quadgram_mle(i) for i in lst]\n",
    "        ans = list(np.random.multinomial(1,plst))\n",
    "        ind = ans.index(1)\n",
    "        \n",
    "        new_word = lst[ind][-1]\n",
    "        sent=sent+\" \"+new_word\n",
    "        if (new_word=='</s>'):\n",
    "            break\n",
    "        else:\n",
    "            start = (start[1],start[2],new_word)\n",
    "    \n",
    "    return sent[4:-5]\n",
    "\n",
    "for i in range(10):\n",
    "    print(quad_generate())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k is model_name\n",
    "# k=1 bigram\n",
    "# k=2 trigram\n",
    "# k=3 quadgram\n",
    "def generate(k):\n",
    "    if k==1:\n",
    "        return bi_generate()\n",
    "    elif k==2:\n",
    "        return tri_generate()\n",
    "    elif k==3:\n",
    "        return quad_generate()\n",
    "    else:\n",
    "        return \"Model no. not valid\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability of a sentence given Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the value of k, we compute probabilities using the given approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k=4 and k=5 use probabilities calculated using counts after applying add 1 smoothing and good turing smoothing respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.532009474007149e-10\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# k is model_name\n",
    "# k=0 unigram\n",
    "# k=1 bigram\n",
    "# k=2 trigram\n",
    "# k=3 quadgram\n",
    "# k=4 bigram probability after add 1 smoothing\n",
    "# k=5 bigram probability after good turing smoothing\n",
    "\n",
    "def log_prob_of_sent(sentence,k):\n",
    "    \n",
    "    if k==0:\n",
    "        pro=0\n",
    "        for i in range(len(sentence)):\n",
    "            pro+=math.log(unigram_mle(sentence[i]))\n",
    "        return pro\n",
    "    \n",
    "    elif k==1:\n",
    "        pro=math.log(unigram_mle(sentence[0]))\n",
    "        for i in range(len(sentence)-1):\n",
    "            pro+=math.log(bigram_mle(sentence[i:i+2]))\n",
    "        return pro\n",
    "    \n",
    "    elif k==2:\n",
    "        pro=math.log(unigram_mle(sentence[0]))+math.log(bigram_mle(sentence[0:2]))\n",
    "        for i in range(len(sentence)-2):\n",
    "            pro+=math.log(trigram_mle(sentence[i:i+3]))\n",
    "        return pro\n",
    "    \n",
    "    elif k==3:\n",
    "        pro=math.log(unigram_mle(sentence[0]))+math.log(bigram_mle(sentence[0:2]))+math.log(trigram_mle(sentence[0:3]))\n",
    "        for i in range(len(sentence)-3):\n",
    "            pro+=math.log(quadgram_mle(sentence[i:i+4]))\n",
    "        return pro\n",
    "    \n",
    "    # the function add1_prob() is defined below, run that cell first\n",
    "    elif k==4:\n",
    "        pro=math.log(unigram_mle(sentence[0]))\n",
    "        for i in range(len(sentence)-1):\n",
    "            pro+=math.log(add1_prob(sentence[i:i+2]))\n",
    "        return pro\n",
    "\n",
    "    # the function good_turing_prob() is defined below, run that cell first\n",
    "    elif k==5:\n",
    "        pro=math.log(unigram_mle(sentence[0]))\n",
    "        for i in range(len(sentence)-1):\n",
    "            val = math.log(good_turing_prob(sentence[i:i+2]))\n",
    "            pro=pro+val\n",
    "        return pro\n",
    "        \n",
    "# Pick some sentence in the form shown below to calculate its probability\n",
    "sentence=('<s>', 'who', 'could', 'come', 'to-night', '?', '</s>')\n",
    "for k in [5] : \n",
    "    print(math.exp(log_prob_of_sent(sentence,k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add 1 Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function add1_bigram_count can be used to calculate the count of any possible bigram from the corpus post add 1 smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.43718147573676\n"
     ]
    }
   ],
   "source": [
    "def add1_bigram_count(i,j):\n",
    "    if (i,j) in bigram.keys():\n",
    "        count = (bigram[(i,j)]+1)*(unigram[i])/(unigram[i]+n_unigram)\n",
    "    else:\n",
    "        count =(unigram[i])/(unigram[i]+n_unigram)\n",
    "    return count\n",
    "\n",
    "print(add1_bigram_count('in', 'the'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add1_prob(words):\n",
    "    if words in bigram.keys():\n",
    "        pro = (bigram[words]+1)/(unigram[words[0]]+n_unigram)\n",
    "    else:\n",
    "        pro = 1/(unigram[words[0]]+n_unigram)\n",
    "    return pro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Good Turing Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.2984770319112786  :  0.7015229680887214\n",
      "2 1.156903332643345  :  0.8430966673566549\n",
      "3 2.0182501341921633  :  0.9817498658078367\n",
      "4 2.734042553191489  :  1.2659574468085109\n",
      "5 3.88715953307393  :  1.11284046692607\n",
      "6 5.465465465465465  :  0.5345345345345347\n",
      "7 6.3076923076923075  :  0.6923076923076925\n",
      "8 7.682926829268292  :  0.3170731707317076\n",
      "9 6.742857142857143  :  2.257142857142857\n",
      "32371\n",
      "4831\n",
      "1863\n",
      "940\n",
      "514\n",
      "333\n",
      "260\n",
      "205\n",
      "175\n"
     ]
    }
   ],
   "source": [
    "bilst=list(bigram.values())\n",
    "fof=dict()  # fof or frequency of frequencies\n",
    "for i in range(len(bilst)):\n",
    "    if bilst[i] not in fof:\n",
    "        fof[bilst[i]]=1\n",
    "    else:\n",
    "        fof[bilst[i]]+=1\n",
    "\n",
    "def good_turing_count(i):\n",
    "    return fof[i+1]*(i+1)/fof[i]\n",
    "\n",
    "for i in range(1,10):\n",
    "    print (i ,good_turing_count(i),\" : \", i-good_turing_count(i))\n",
    "    \n",
    "#print(fof)\n",
    "for i in range(1,10):\n",
    "    print(fof[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average discounting value :  0.9673584077449541\n"
     ]
    }
   ],
   "source": [
    "dsum=0\n",
    "for i in range(1,10):\n",
    "    dsum+= i-good_turing_count(i)\n",
    "\n",
    "discount_val = dsum/9.0\n",
    "    \n",
    "print (\"Average discounting value : \",discount_val)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On an average over different training datasets, I saw that the avg discounting value is around 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00039062500000000035\n"
     ]
    }
   ],
   "source": [
    "def good_turing_prob(words):\n",
    "    discount_val=0.95\n",
    "    if words in bigram.keys():\n",
    "        i=bigram[words]\n",
    "        pro = (i - discount_val)/unigram[words[0]]\n",
    "    else:\n",
    "        pro = fof[1]/(len(bilst))\n",
    "    return pro\n",
    "print(good_turing_prob(('come', 'to-night')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests=[]\n",
    "del_lst=[',','.',\"'s\",'\"','“','”',':','--',\"'\",\"!\",\"''\",'``',';']\n",
    "\n",
    "for i in range(len(testing_data)):\n",
    "    tests.append('<s>')\n",
    "    tests_in_line=word_tokenize(testing_data[i])\n",
    "    for j in range(len(tests_in_line)):\n",
    "        if tests_in_line[j] not in del_lst:\n",
    "            tests.append(tests_in_line[j])\n",
    "    tests.append('</s>')\n",
    "#print(tests) #Remove # to print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "test_lst=[]\n",
    "test_sent=[]\n",
    "for i in range(len(tests)):\n",
    "    test_sent.append(tests[i])\n",
    "    if (tests[i]=='</s>'):\n",
    "        test_lst.append(tuple(test_sent))\n",
    "        test_sent=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity using add 1 smoothing is :  1056.8183180947944\n"
     ]
    }
   ],
   "source": [
    "log_pro = log_prob_of_sent(tuple(tests),4)\n",
    "perp = math.exp(-1*log_pro/len(tests))\n",
    "\n",
    "print (\"Perplexity using add 1 smoothing is : \",perp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity using good turing smoothing is :  14.402676140693398\n"
     ]
    }
   ],
   "source": [
    "log_pro = log_prob_of_sent(tuple(tests),5)\n",
    "perp = math.exp(-1*log_pro/len(tests))\n",
    "\n",
    "print (\"Perplexity using good turing smoothing is : \",perp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
